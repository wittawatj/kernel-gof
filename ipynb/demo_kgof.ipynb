{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to `fsic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will introduce you to  `fsic`, a Python package for nonparameteric independence testing. See the [Github page](https://github.com/wittawatj/fsic-test) of `fsic` for more information. \n",
    "\n",
    "Make sure that you have `fsic` included in Python's search path. In particular the following import statements should not produce any fatal error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import fsic.util as util\n",
    "import fsic.data as data\n",
    "import fsic.kernel as kernel\n",
    "import fsic.indtest as it\n",
    "import fsic.glo as glo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: NFSIC Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NFSIC (Normalized Finite Set Independence Criterion) is an indepedence test proposing a null hypothesis \n",
    "\n",
    "$H_0: X \\text{ and } Y \\text{ are independent }$\n",
    "\n",
    "against an alternative hypothesis\n",
    "\n",
    "$H_1: X \\text{ and } Y \\text{ are dependent }$\n",
    "\n",
    "where $X \\in \\mathbb{R}^{d_x}, Y \\in \\mathbb{R}^{d_y}$ are random variables. For demonstration purpose, let us consider a simple one-dimensional toy problem in which $X,Y$ are known to be dependent i.e., $H_1$ is true. This problem is what we refer to as the Sinusoid problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinusoid problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Sinusoid problem, $X, Y \\in [-\\pi, \\pi]$ and the joint probability density is given by \n",
    "\n",
    "$p_{xy}(x, y) \\propto 1 + \\sin(\\omega x)\\sin(\\omega y)$\n",
    "\n",
    "where $\\omega$ is the frequency of the sinusoid controlling the difficulty of the problem (i.e., the higher the $\\omega$, the more difficult to detect the dependence). We will use $\\omega=1$. A plot of the sample drawn from this model is shown below.\n",
    "\n",
    "In this framework, a toy problem is represented by a `PairedSource` object (a source of paired sample). Many toy problems are included in `fsic.data` module. Classes implementing a `PairedSource` have names starting with `PS`. Here, we will construct a `PS2DSinFreq` which implements the Sinusoid problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "omega = 1\n",
    "ps = data.PS2DSinFreq(freq=omega)\n",
    "\n",
    "# There are many more PairedSource implmentations.\n",
    "#ps = data.PSIndSameGauss(dx, dy)\n",
    "#ps = data.PS2DUnifRotate(angle=np.pi/4)\n",
    "#ps = data.PSUnifRotateNoise(angle=np.pi/3, noise_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Significance level of the test\n",
    "alpha = 0.01\n",
    "\n",
    "# Number of paired samples to draw\n",
    "n = 1000\n",
    "\n",
    "# Random seed\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw n paired samples from the PairedSource with the random seed\n",
    "pdata = ps.sample(n, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drawn sample from a `PairedSource` is represented as an object of `PairedData` class. A `PairedData` object is just an encapsulation of the paired sample $(X, Y)$. The `PairedData` object will be fed to a testing algorithm to conduct the independence test.\n",
    "\n",
    "In practice, we have access to only data matrices X, an $(n \\times d_x)$ matrix, and Y, an $(n \\times d_y)$ matrix. We can also directly construct a `PairedData` with \n",
    "\n",
    "    pdata = data.PairedData(X, Y)\n",
    "    \n",
    "Here, we sample it from a `PairedSource`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's plot the data.\n",
    "X, Y = pdata.xy()\n",
    "plt.plot(X, Y, 'k.')\n",
    "plt.xlim([-np.pi, np.pi])\n",
    "plt.ylim([-np.pi, np.pi])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have `pdata`, let us randomly split it into two disjoint halves: `tr` and `te`. The training set `tr` will be used for parameter optimization. The testing set `te` will be used for the actual independence test. `tr` and `tr` are of type `PairedData`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr, te = pdata.split_tr_te(tr_proportion=0.5, seed=seed+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us optimize the parameters of NFSIC on `tr`. The optimization relies on `theano` to compute the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# J is the number of test locations\n",
    "J = 1\n",
    "\n",
    "# There are many options for the optimization. \n",
    "# Almost all of them have default values. \n",
    "# Here, we will list a few to give you a sense of what you can control.\n",
    "op = {\n",
    "    'n_test_locs':J,  # number of test locations\n",
    "    'max_iter':200, # maximum number of gradient ascent iterations\n",
    "    'V_step':1, # Step size for the test locations of X\n",
    "    'W_step':1, # Step size for the test locations of Y\n",
    "    'gwidthx_step':1, # Step size for the Gaussian width of X\n",
    "    'gwidthy_step':1, # Step size for the Gaussian width of Y\n",
    "    'tol_fun':1e-4, # Stop if the objective function does not increase more than this\n",
    "    'seed':seed+7 # random seed\n",
    "}\n",
    "\n",
    "# Do the optimization with the options in op.\n",
    "op_V, op_W, op_gwx, op_gwy, info = it.GaussNFSIC.optimize_locs_widths(tr, alpha, **op )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization procedure returns back \n",
    "\n",
    "1. `op_V`: optimized test locations (features) for $X$. A $J \\times d_x$ numpy array.\n",
    "2. `op_W`: optimized test locations for $Y$. A $J \\times d_y$ numpy array.\n",
    "3. `op_gwx`: optimized Gaussian width (for Gaussian kernels) for $X$. A floating point number.\n",
    "4. `op_gwy`: optimized Gaussian width (for Gaussian kernels) for $Y$. A floating point number.\n",
    "5. `info`: information gathered during the optimization i.e., variable trajectories. A dictionary.\n",
    "\n",
    "Let us use these values to construct an NFSIC test. An NFSIC test using Gaussian kernels is implemented in `fsic.indtest.GaussNFSIC`. This is the same as using `fsic.indtest.NFSIC` which is a generic implementation with Gaussian kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfsic_opt = it.GaussNFSIC(op_gwx, op_gwy, op_V, op_W, alpha)\n",
    "\n",
    "# This is the same as \n",
    "#k = kernel.KGauss(op_gwx)\n",
    "#l = kernel.KGauss(op_gwy)\n",
    "#nfsic_opt = it.NFSIC(k, l, op_V, op_W, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the independence test on the testing data `te`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return a dictionary of testing results\n",
    "nfsic_opt.perform_test(te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the test correctly rejects $H_0$ with a very small p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned test location(s)\n",
    "\n",
    "Let us check the optimized test locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's plot the locations on top of the data\n",
    "xtr, ytr = tr.xy()\n",
    "plt.plot(X, Y, 'k.', label='Data')\n",
    "plt.plot(op_V, op_W, 'r*', label='Test location', markersize=20)\n",
    "plt.xlim([-np.pi, np.pi])\n",
    "plt.ylim([-np.pi, np.pi])\n",
    "plt.title('Training data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(numpoints=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the learned location(s) to be in the region where $p(x, y)$ differs most from $p(x)p(y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise \n",
    "Go back to where we define the `PairedSource`, and change `omega` to 0. This makes $(X, Y) \\sim U([-\\pi, \\pi]^2)$. In this case, $X$ and $Y$ are independent i.e., $H_0$ is true. Run the whole procedure again and verify that the test will not reject $H_0$. (Technically, the probability of rejecting is about $\\alpha$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
